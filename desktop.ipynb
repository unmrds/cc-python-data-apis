{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading data from the desktop file system\n",
    "\n",
    "The goal of this notebook session is to read a \"comma separated value\" data file from the computer desktop and load it into a usable Python data structure that can be used for further analysis. In this section, we will explore Python tools for reading a text file line-by-line into an array-like `list`, parsing and cleaning the contents of each line, and then converting the line data elements from string types to their corresponding data types.\n",
    "\n",
    "The data we will use in this session is from a non-active research site of the *Long Term Ecological Research Network*, called *North Inlet LTER*. The data consist of daily water samples from from 1978 to 1992. This data is available from the *Environmental Data Initiative* (EDI) [data repository](https://portal.edirepository.org/nis) under the repository identifier [knb-lter-nin.1.1](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-nin&identifier=1).\n",
    "\n",
    "#### References\n",
    "\n",
    " 1. Python `with`\n",
    "    1. [Python 3 reference](https://docs.python.org/3/reference/compound_stmts.html#with) \n",
    "    1. A `with` [Anti-pattern](https://docs.quantifiedcode.com/python-anti-patterns/maintainability/not_using_with_to_open_files.html) or when/how `with` should be used.\n",
    " 1. Python `list`\n",
    "     1. [Python 3 reference](https://docs.python.org/3.6/library/stdtypes.html#list)\n",
    "     1. [Tutorial](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)\n",
    "     1. `list` [comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)\n",
    " 1. Python`array`\n",
    "     1. [Python 3 reference](https://docs.python.org/3/library/array.html)\n",
    "     1. *arrays* **are not** *lists* [stackoverflow](https://stackoverflow.com/questions/176011/python-list-vs-array-when-to-use?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    " 1. Python `dictionary`\n",
    "     1.[Python 3 reference](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)\n",
    "     1.[Tutorial](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)\n",
    " 1. [Matplotlib](https://matplotlib.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and verify our data file `LTER.NIN.DWS.csv` using BASH shell commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -X GET https://pasta.lternet.edu/package/data/eml/knb-lter-nin/1/1/DailyWaterSample-NIN-LTER-1978-1992 > LTER.NIN.DWS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10 ./LTER.NIN.DWS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tail -n 10 ./LTER.NIN.DWS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l ./LTER.NIN.DWS.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data table file `LTER.NIN.DWS.csv`and load into a multi-dimensional Python `list` data structure.\n",
    "\n",
    "The data file we are using consists of text that is formatted as a \"comma separated values\" table, with a mixture of column data types, including dates, text, floating point, and interger values. As with most software, Python reads text files a line at a time, as delimitted by the single line feed character `\\n`. This line feed is consider white space and should be removed from the end of each line.\n",
    "\n",
    "Because the file is text, each full line is read and saved as a Python string. In Python 3, strings (or `str`) are composed of Unicode characters. A discussion of Unicode is beyond the scope of this session, but there are plenty of sites on the Internet that provide good information on the subject ([Python 3 reference](https://docs.python.org/3.6/howto/unicode.html?highlight=unicode), [How Python does Unicode](https://www.b-list.org/weblog/2017/sep/05/how-python-does-unicode/), [Pragmatic Unicode, or How do I stop the pain?](https://www.youtube.com/watch?v=sgHbC6udIqc), and [Characters, Symbols and the Unicode Miracle](https://youtu.be/MijmeoH9LT4)).\n",
    "\n",
    "The Python `with` statement creates a context in which scope-bounded execution can occur. Using the `with` statement for file operations is recommended because the file handle will be closed automatically, even if an exception occurs during the read operation.\n",
    "\n",
    "The commad in the square brackets `[]` is a Python `list comprehension`, which is generally considered to be more efficient than using a `for` statement and it is more compact.\n",
    "\n",
    "These two commands will generate a Python `list` data structure, but not quite the one we need for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./LTER.NIN.DWS.csv', 'r') as f: # Open text file for reading\n",
    "    table = [_.strip().split(',') for _ in f.readlines()] # <-- list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head in table[:9]:\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tail in table[-10:]:\n",
    "    print(tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = table[0] # Set header from original table\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[1:] # Remove header; extract only string values that represent the real table data\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the `str` values into the appropriate data types.\n",
    "\n",
    "For us to use the data contained within this file, each line must be parsed into its respective data tokens and converted into their real data types (e.g., date, float, integer, ...). There are some good Python packages that can guess at the conversion, but we will manually peform this task since we too can make a good guess as to the data types.\n",
    "\n",
    "The result of this process will be a multi-dimensional Python `list` data structure that holds the data - you can think of this as a 2-dimensional array. When creating this `list` data structure, we can order the table in two ways: 1) row major or 2) column major."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row major order\n",
    "\n",
    "*Row major order* means that data are ordered in the same way that they were read in from the data file: as a single line consisting of a single data point from each data column that is store in a row-based `list`.\n",
    "\n",
    "```\n",
    "[pnt1-col1, pnt1-col2, pnt1-col3, pnt1-col4,...]\n",
    "[pnt2-col1, pnt2-col2, pnt2-col3, pnt2-col4,...]\n",
    ".\n",
    ".\n",
    ".\n",
    "[pntN-col1, pntN-col2, pntN-col3, pntN-col4,...]\n",
    "```\n",
    "\n",
    "This may seem more natural when processing the data table for printing or examination, but it does not capture the columnar model of the actual table and results in more work when performing downstream analysis of a single data column because you must iterate through each row and select the data point of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate data frame with coerced (converted) values from data table in row-major order\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df = []\n",
    "for row in table:\n",
    "    data = []\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y')\n",
    "    data.append(date)             # Date as datetime\n",
    "    data.append(row[1])          # transect as unicode string\n",
    "    data.append(float(row[2]))   # water_temp as float\n",
    "    data.append(float(row[3]))   # SAL as float\n",
    "    data.append(float(row[4]))   # TNW as float\n",
    "    data.append(float(row[5]))   # TNF as float\n",
    "    data.append(float(row[6]))   # TPW as float\n",
    "    data.append(float(row[7]))   # TPF as float\n",
    "    data.append(float(row[8]))   # POP as float\n",
    "    data.append(float(row[9]))   # NHN as float\n",
    "    data.append(float(row[10]))  # NNN as float\n",
    "    data.append(int(row[11]))    # CHEM as integer\n",
    "    data.append(float(row[12]))  # TOC as float\n",
    "    data.append(float(row[13]))  # DOC as float\n",
    "    data.append(float(row[14]))  # POC as float\n",
    "    df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"Date\" and \"water_temp\" columns and plot the data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = []\n",
    "water_temp = []\n",
    "for row in df:\n",
    "    date.append(row[0])\n",
    "    water_temp.append(row[2])\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date, water_temp, label='Water Temp')\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column major order\n",
    "\n",
    "*Column major order* means that the data are ordered within their respective column structure and can be accessed as a single `list`.\n",
    "\n",
    "```\n",
    "[pnt1-col1], [pnt1-col2], [pnt1-col3], [pnt1-col4]...\n",
    "[pnt2-col1], [pnt2-col2], [pnt2-col3], [pnt2-col4]...\n",
    ".\n",
    ".\n",
    ".\n",
    "[pntN-col1], [pntN-col2], [pntN-col3], [pntN-col4]...\n",
    "```\n",
    "\n",
    "Building the column major order `list` data structure requires minimal effort and results in a much more functional data structure for performing column-based data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate data frame with coerced (converted) values from data table in column-major order\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "for row in table:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y')\n",
    "    df[0].append(date)              # Date as datetime\n",
    "    df[1].append(row[1])           # transect as unicode string\n",
    "    df[2].append(float(row[2]))    # water_temp as float\n",
    "    df[3].append(float(row[3]))    # SAL as float\n",
    "    df[4].append(float(row[4]))    # TNW as float\n",
    "    df[5].append(float(row[5]))    # TNF as float\n",
    "    df[6].append(float(row[6]))    # TPW as float\n",
    "    df[7].append(float(row[7]))    # TPF as float\n",
    "    df[8].append(float(row[8]))    # POP as float\n",
    "    df[9].append(float(row[9]))    # NHN as float\n",
    "    df[10].append(float(row[10]))  # NNN as float\n",
    "    df[11].append(int(row[11]))    # CHEM as integer\n",
    "    df[12].append(float(row[12]))  # TOC as float\n",
    "    df[13].append(float(row[13]))  # DOC as float\n",
    "    df[14].append(float(row[14]))  # POC as float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"Date\" and \"water_temp\" columns and plot the data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = df[0]\n",
    "water_temp = df[2]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date, water_temp, label='Water Temp')\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a more efficient (storage and speed) data structure using the Python `array` to store data.\n",
    "\n",
    "Python `array` data structures are closely aligned with the underlying and native \"C\" data types used in the implementation of the Python language. As such, these data structures are based on true types (not Object types like in Python), so they are much more efficient in storage and can be processed much faster during script execution.\n",
    "\n",
    "The following code demonstrates how to implement a *column major order* data table similar to the Python `list` data strucutre above. It also uses the Python `dict` data structure, which provides a \"key-value\" associative capability so that we may refer to our columns using their respective names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty data frame data structure as Python dictionary\n",
    "\n",
    "import array\n",
    "df = {\n",
    "    'Date': [],                      # datetime object\n",
    "    'transect': [],                  # unicode string\n",
    "    'water_temp': array.array('d'),  # double float\n",
    "    'SAL': array.array('d'),         # double float\n",
    "    'TNW': array.array('d'),         # double float\n",
    "    'TNF': array.array('d'),         # double float\n",
    "    'TPW': array.array('d'),         # double float\n",
    "    'TPF': array.array('d'),         # double float\n",
    "    'POP': array.array('d'),         # double float\n",
    "    'NHN': array.array('d'),         # double float\n",
    "    'NNN': array.array('d'),         # double float\n",
    "    'CHEM': array.array('l'),        # signed long\n",
    "    'TOC': array.array('d'),         # double float\n",
    "    'DOC': array.array('d'),         # double float\n",
    "    'POC': array.array('d')          # double float\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate data frame with coerced (converted) values from data table in column-major order\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "for row in table:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y')\n",
    "    df['Date'].append(date)                  # Date as datetime\n",
    "    df['transect'].append(row[1])           # transect as unicode string\n",
    "    df['water_temp'].append(float(row[2]))  # water_temp as float object\n",
    "    df['SAL'].append(float(row[3]))         # SAL as float object\n",
    "    df['TNW'].append(float(row[4]))         # TNW as float object\n",
    "    df['TNF'].append(float(row[5]))         # TNF as float object\n",
    "    df['TPW'].append(float(row[6]))         # TPW as float object\n",
    "    df['TPF'].append(float(row[7]))         # TPF as float object\n",
    "    df['POP'].append(float(row[8]))         # POP as float object\n",
    "    df['NHN'].append(float(row[9]))         # NHN as float object\n",
    "    df['NNN'].append(float(row[10]))        # NNN as float object\n",
    "    df['CHEM'].append(int(row[11]))         # CHEM as integer object\n",
    "    df['TOC'].append(float(row[12]))        # TOC as float object\n",
    "    df['DOC'].append(float(row[13]))        # DOC as float object\n",
    "    df['POC'].append(float(row[14]))        # POC as float object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['CHEM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"Date\" and \"water_temp\" columns and plot the data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = df['Date']\n",
    "water_temp = df['water_temp']\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date, water_temp, label='Water Temp')\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unm",
   "language": "python",
   "name": "unm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
