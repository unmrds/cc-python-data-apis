{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reading data from a REST web service API\n",
    "\n",
    "The goal of this notebook session is to read a \"comma separated value\" data file from a REST web service API of a data repository and load it into a usable Python data structure that can be used for further analysis. In this section, we will explore Python tools to read a REST web service end point and download data directly into a Python data structure.\n",
    "\n",
    "`REST` (*Re*spresentational *S*tate *T*ransfer) relies on the existing HTTP verbs (e.g., `POST`, `GET`, `PUT`, and `DELETE`) and request-response patterns to effectively support the actions of a standard application programmable interface (API) for creating a software excution environment of an Internet client/server model. The most common REST action for a web client is to *read* a web-based resource (a data file, for example) from a web server using the HTTP `GET` request method. The four verbs listed above provide the core web-services for *Create*, *Read*, *Update*, and *Delete* methods of REST-based applications. The benefit of REST web services is that the web-client and web-server execution stack can be implemented using completely different software environemnts and different operating systems.\n",
    "\n",
    "<img src='./web-service.png'/>\n",
    "\n",
    "The data we will use in this session is from a non-active research site of the *Long Term Ecological Research Network*, called *North Inlet LTER*. The data consist of daily water samples from from 1978 to 1992. This data is available from the *Environmental Data Initiative* (EDI) [data repository](https://portal.edirepository.org/nis) under the repository identifier [knb-lter-nin.1.1](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-nin&identifier=1).\n",
    "\n",
    "The EDI data repository software, called *PASTA*, provides a full web-service API that allows data producers to upload data packages to the repository using HTTP `POST` and `PUT` verbs, as well as data package reading services using the HTTP `GET` verb for data consumers. We will use the Python `requests` package to access the data file of data package knb-lter-nin.1.1 and load it into a Python data structure. The PASTA API method that we will use is called [*Read Data Entity*](https://pasta.lternet.edu/package/docs/api#GET%20:%20/data/eml/{scope}/{identifier}/{revision}/{entityId}).\n",
    "\n",
    "#### References\n",
    "1. Environmental Data Initiative [data portal](https://portal.edirepository.org/nis)\n",
    "1. PASTA+ web service API at [read the docs](http://pastaplus-core.readthedocs.io/en/latest/index.html)\n",
    "1. Python [requests](http://docs.python-requests.org/en/master/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python `requests` using `pip` from BASH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download our data file `LTER.NIN.DWS.csv` from the PASTA data repository using the Python `requests` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pasta.lternet.edu/package/data/eml/knb-lter-nin/1/1/DailyWaterSample-NIN-LTER-1978-1992'\n",
    "r = requests.get(url) # Fetch the data directly from the PASTA data repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{code}: {msg}'.format(code=r.status_code, msg=r.reason))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for header in r.headers:\n",
    "    print('{header}: {value}'.format(header=header, value=r.headers[header]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text[:256] # Display first 256 characters of response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [ _.split(',') for _ in r.text.strip().split('\\r\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = table[0] # Set header from original table\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[1:] # Remove header; extract only string values that represent the real table data\n",
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate data frame with coerced (converted) values from data table in column-major order\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "for row in table:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y')\n",
    "    df[0].append(date)              # Date as datetime\n",
    "    df[1].append(row[1])           # transect as unicode string\n",
    "    df[2].append(float(row[2]))    # water_temp as float\n",
    "    df[3].append(float(row[3]))    # SAL as float\n",
    "    df[4].append(float(row[4]))    # TNW as float\n",
    "    df[5].append(float(row[5]))    # TNF as float\n",
    "    df[6].append(float(row[6]))    # TPW as float\n",
    "    df[7].append(float(row[7]))    # TPF as float\n",
    "    df[8].append(float(row[8]))    # POP as float\n",
    "    df[9].append(float(row[9]))    # NHN as float\n",
    "    df[10].append(float(row[10]))  # NNN as float\n",
    "    df[11].append(int(row[11]))    # CHEM as integer\n",
    "    df[12].append(float(row[12]))  # TOC as float\n",
    "    df[13].append(float(row[13]))  # DOC as float\n",
    "    df[14].append(float(row[14]))  # POC as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"Date\" and \"water_temp\" columns and plot the data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = df[0]\n",
    "water_temp = df[2]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date, water_temp, label='Water Temp')\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unm",
   "language": "python",
   "name": "unm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
