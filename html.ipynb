{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading data from an HTML web page\n",
    "\n",
    "The goal of this notebook session is to read a data file that is displayed as an \"HTML table\" on a website. HTML consists of text that is enclosed by descriptive tags, which dictate how it is displayed in a web browser. The set of tags, bounded by angle brackets `<` and `>`, are unique and provide the web browser a clue as to how they should be displayed. For example, the `<table>` tag indicates that a 2-dimensional table structure is to follow. Rows in the table are bounded by `<tr>` tags, and delineate either a header row (with `<th>` tags) or data row (with `<td>` tags).\n",
    "\n",
    "<img src='./table_html.png/' width='55%'/>\n",
    "\n",
    "The data we will use in this session is from a non-active research site of the *Long Term Ecological Research Network*, called *North Inlet LTER*. The data consist of daily water samples from from 1978 to 1992. This data is available from the *Environmental Data Initiative* (EDI) [data repository](https://portal.edirepository.org/nis) under the repository identifier [knb-lter-nin.1.1](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-nin&identifier=1).\n",
    "\n",
    "Although we do not have a website from which to scrape this data table, the HTML data table can be loaded from the desktop and operated on as if you did download it directly from a website. We will use a Python package called `BeautifulSoup` to parse and scrape the HTML. BeautifulSoup reads the full HTML page and creates a memory-based document object model (tree-like hierarchy) of the page structure and content. To access the data table, we will focus on finding the `<table>` element, which builds a data table object of header and data rows. From the data table object, we will skip the header row and parse only rows that contain the `<td>` data element tag into a Python `list` data structure.\n",
    "\n",
    "Sidenote: If you were to install the Python `requests` package, you could use the following code to download an HTML web page for pasring and scraping by BeautifulSoup:\n",
    "\n",
    "```Python\n",
    "import requests\n",
    "\n",
    "url = 'https://datawebsite.org/data.html\n",
    "r = requests.get(url)\n",
    "html_data_table = r.text\n",
    "```\n",
    "\n",
    "#### References\n",
    "\n",
    "1. [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#)\n",
    "1. [lxml](http://lxml.de/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data table HTML file `data.html` into a `BeautifulSoup` webpage DOM object. \n",
    "\n",
    "The \"data.html\" is the same data as found in the `LTER.NIN.DWS.csv` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('./data.html', 'r') as f: # Open html file for reading\n",
    "    soup = BeautifulSoup(f, 'lxml') # Create a beautiful soup DOM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = soup.find('table') # Find the single, known data table tag object in the HTML web page\n",
    "table_rows = html_table('tr') # Returns a list of \"<tr>\" tag objects\n",
    "\n",
    "table = []\n",
    "for table_row in table_rows[1:]:\n",
    "    row = []\n",
    "    row_data = table_row('td') # Returns a list of \"<td>\" tag objects\n",
    "    for data_token in row_data:\n",
    "        row.append(data_token.text) # Extract the text contents of the \"<td>\" element\n",
    "    table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head in table[:9]:\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate data frame with coerced (converted) values from data table in column-major order\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "for row in table:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y')\n",
    "    df[0].append(date)              # Date as datetime\n",
    "    df[1].append(row[1])           # transect as unicode string\n",
    "    df[2].append(float(row[2]))    # water_temp as float\n",
    "    df[3].append(float(row[3]))    # SAL as float\n",
    "    df[4].append(float(row[4]))    # TNW as float\n",
    "    df[5].append(float(row[5]))    # TNF as float\n",
    "    df[6].append(float(row[6]))    # TPW as float\n",
    "    df[7].append(float(row[7]))    # TPF as float\n",
    "    df[8].append(float(row[8]))    # POP as float\n",
    "    df[9].append(float(row[9]))    # NHN as float\n",
    "    df[10].append(float(row[10]))  # NNN as float\n",
    "    df[11].append(int(row[11]))    # CHEM as integer\n",
    "    df[12].append(float(row[12]))  # TOC as float\n",
    "    df[13].append(float(row[13]))  # DOC as float\n",
    "    df[14].append(float(row[14]))  # POC as float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"Date\" and \"water_temp\" columns and plot the data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = df[0]\n",
    "water_temp = df[2]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date, water_temp, label='Water Temp')\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unm",
   "language": "python",
   "name": "unm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
